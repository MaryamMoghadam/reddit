{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "beP1lxinx0j_"
   },
   "source": [
    "### TODO:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### IDEAS\n",
    "How is this affecting di\n",
    "* This could be an ongoing project with a website track how events affect different disorders and suicidal posts\n",
    "* Build models detecting each subreddit. Then use prob for seeing how anxious, paranoid, etc, each post is. And I think most will become more similar to anxiety as corona virus increases\n",
    "* predict flu trends (CDC) with healthanxiety posts\n",
    "* Predict if post is from a certain disorder, is suicidal, pre or post coronavirus,  \n",
    "* model this with important events: https://towardsdatascience.com/inferring-causality-in-time-series-data-\n",
    "* How is coronavirus affecting divorce/finance?\n",
    "* How is health anxiety - social anxiety - mindfulness\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22729,
     "status": "ok",
     "timestamp": 1587255224885,
     "user": {
      "displayName": "Tanya Talkar",
      "photoUrl": "",
      "userId": "12952569726622083567"
     },
     "user_tz": 240
    },
    "id": "Cdcox0u7x4Hu",
    "outputId": "edd837e3-596c-495e-c1c9-ce8d3dd2c394"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c6f6feeaa620>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run this cell to be able to mount GDrive and attach it to the colab so that we can save json outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# Run this cell to be able to mount GDrive and attach it to the colab so that we can save json outputs\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JM2YlSCpx0kA"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c2b97689e58f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpress\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraph_objs\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Authors: Daniel M. Low\n",
    "License: Apache 2.0\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from pprint import pprint\n",
    "import requests\n",
    "import time\n",
    "\n",
    "from datetime import datetime, date, timedelta\n",
    "import string\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import cm\n",
    "import plotly.express as px\n",
    "from plotly import graph_objs as go\n",
    "\n",
    "# sys.path.append('./../../catpro')\n",
    "# from catpro.preprocessing_text.extract_features import liwc, words, punctuation_count, sentiment_analysis, count_words, tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l-kKn65hx0kD"
   },
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import chart_studio.plotly as py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RJmTQqK1x0kE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vp2Ulh2Ix0kG"
   },
   "outputs": [],
   "source": [
    "def date2timestamp(date):\n",
    "    '''\n",
    "    \"01/12/2011\"\n",
    "    '''\n",
    "    return int(time.mktime(datetime.strptime(date, \"%Y/%m/%d\").timetuple()))\n",
    "\n",
    "def timestamp2date(unix_timestamp):\n",
    "    '''\n",
    "    1284101485\n",
    "    # if you encounter a \"year is out of range\" error the timestamp\n",
    "    # may be in milliseconds, try `ts /= 1000` in that case\n",
    "    print()\n",
    "    '''\n",
    "    return datetime.utcfromtimestamp(unix_timestamp).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "def url2json(url, output_filepath):\n",
    "    solditems = requests.get(url) # (your url)\n",
    "    data = solditems.json()\n",
    "    with open(output_filepath+'.json', 'w') as f:\n",
    "        json.dump(data, f)\n",
    "    return\n",
    "\n",
    "def json2list(json_filepath):\n",
    "    with open(json_filepath) as f:\n",
    "        data = json.load(f)['data']\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def list_of_days(start_date, end_date):\n",
    "    '''\n",
    "    start_date = date(2019, 1, 19)   # start date\n",
    "    end_date = date(2019, 3, 22)   # end date\n",
    "    '''\n",
    "    delta = end_date - start_date       # as timedelta\n",
    "    days = []\n",
    "    for i in range(delta.days + 1):\n",
    "        day = start_date + timedelta(days=i)\n",
    "        days.append(str(day).replace('-', '/'))\n",
    "    return days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u_I1EGy5x0kJ"
   },
   "outputs": [],
   "source": [
    "# input y variable across time\n",
    "\n",
    "\n",
    "def plot_across_time(subreddits, x = None, y_col = '', y_col_div_by = '', zscore=False, ylabel='Average negative sentiments',filter_small = True, small_value = 150, plot_raw = True, \n",
    "                     plot_line = True, alpha = 0.3, plot_covid_curves = False):\n",
    "    '''\n",
    "    y_col: {'all_words', ''}\n",
    "    y_col_div_by: {'total_posts'}\n",
    "    small_vale = if you want to include small posts, set to 0. 150 shizophrenia\n",
    "    '''\n",
    "    sns.set(style='white', rc={'figure.figsize':(10,8)}, font_scale =1.5)\n",
    "    cmap = cm.Set3 # tab20c Set3\n",
    "    cmap = cm.jet(np.linspace(0,1,len(subreddits)+1))\n",
    "        \n",
    "    # Load each rubreddit \n",
    "    for i,subreddit in enumerate(subreddits):\n",
    "\n",
    "        df_subreddit = pd.read_csv(output_dir+'features_{}_0.csv'.format(subreddit))\n",
    "        # Some just have avg 10 posts per time segment, so not worth plotting        \n",
    "        total_posts = df_subreddit[['subreddit', 'date']].groupby(['date']).agg(['count']).values\n",
    "        if np.mean(total_posts)  < small_value:\n",
    "            continue\n",
    "        # Load y\n",
    "        if y_col == 'total_posts':\n",
    "            y = total_posts.copy()\n",
    "        else:\n",
    "            y = df_subreddit[[y_col, 'date']].groupby(['date']).agg(['sum']).values\n",
    "        if y_col_div_by == 'total_posts':\n",
    "            y = y/total_posts\n",
    "        \n",
    "        y = [n[0] for n in y]\n",
    "        if zscore:\n",
    "            if len(np.unique(y)) == 1:\n",
    "                # By mistake I downloaded every 3 days and some subreddits max at 1000, so zscore of same values (1000,1000,..., 1000) is not possible                 \n",
    "                continue\n",
    "            else:\n",
    "                y = stats.zscore(y)\n",
    "\n",
    "        # Load x, is the same for all         \n",
    "        if x == None:\n",
    "            x = list(set(df_subreddit['date'].values))\n",
    "            try: x.remove(np.nan)\n",
    "            except: pass\n",
    "            x.sort()\n",
    "        x_num =range(len(x))  \n",
    "        if plot_raw:\n",
    "            plt.plot(x,y, alpha=alpha,color=cmap[i])\n",
    "        if plot_line:\n",
    "            m, b = np.polyfit(x_num, y, 1)\n",
    "            plt.plot(x, m*x_num + b, color=cmap[i], alpha=1,label='r/'+subreddit)\n",
    "        else:\n",
    "            plt.plot(x,y, alpha=1,color=cmap[i],label='r/'+subreddit)\n",
    "    \n",
    "    plt.xticks(ticks=range(len(list(x))), labels=list(x),rotation=90)\n",
    "    \n",
    "    # Plot covid confirmed cases \n",
    "    if plot_covid_curves:\n",
    "        for y_country, country,color in zip(y_countries, countries, ['k','gray','darkgray']):\n",
    "            plt.plot(x,y_country, alpha=1,color=color, label='Confirmed cases - {}'.format(country))\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    if zscore:\n",
    "        ylabel += ' (z-score)'\n",
    "    plt.ylabel(ylabel)\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "epgyIO4Bx0kL"
   },
   "outputs": [],
   "source": [
    "\n",
    "def boxplot_across_time(subreddit, x = None, y_col = '', y_col_div_by = '', zscore=False, ylabel='Average negative sentiments',filter_small = True, small_value = 150, plot_raw = True, \n",
    "                     plot_line = True, alpha = 0.3, plot_covid_curves = False):\n",
    "    '''\n",
    "    y_col: {'all_words', ''}\n",
    "    y_col_div_by: {'total_posts'}\n",
    "    small_vale = if you want to include small posts, set to 0. 150 shizophrenia\n",
    "    '''\n",
    "    sns.set(style='white', rc={'figure.figsize':(10,8)}, font_scale =1.5)\n",
    "    cmap = cm.Set3 # tab20c Set3\n",
    "    cmap = cm.jet(np.linspace(0,1,len(subreddits)+1))\n",
    "        \n",
    "    # Load each rubreddit \n",
    "    for i,subreddit in enumerate(subreddits):\n",
    "\n",
    "        df_subreddit = pd.read_csv(output_dir+'features_{}_0.csv'.format(subreddit))\n",
    "        # Some just have avg 10 posts per time segment, so not worth plotting        \n",
    "        total_posts = df_subreddit[['subreddit', 'date']].groupby(['date']).agg(['count']).values\n",
    "        if np.mean(total_posts)  < small_value:\n",
    "            continue\n",
    "        # Load y\n",
    "        y = df_subreddit[[y_col, 'date']].groupby(['date']).agg(['sum']).values\n",
    "        if y_col_div_by == 'total_posts':\n",
    "            y = y/total_posts\n",
    "        \n",
    "        y = [n[0] for n in y]\n",
    "        if zscore:\n",
    "            if len(np.unique(y)) == 1:\n",
    "                # By mistake I downloaded every 3 days and some subreddits max at 1000, so zscore of same values (1000,1000,..., 1000) is not possible                 \n",
    "                continue\n",
    "            else:\n",
    "                y = stats.zscore(y)\n",
    "\n",
    "        # Load x, is the same for all         \n",
    "        if x == None:\n",
    "            x = list(set(df_subreddit['date'].values))\n",
    "        x_num =range(len(x))  \n",
    "        if plot_raw:\n",
    "            plt.plot(x,y, alpha=alpha,color=cmap[i])\n",
    "        if plot_line:\n",
    "            m, b = np.polyfit(x_num, y, 1)\n",
    "            plt.plot(x, m*x_num + b, color=cmap[i], alpha=1,label='r/'+subreddit)\n",
    "        else:\n",
    "            plt.plot(x,y, alpha=1,color=cmap[i],label='r/'+subreddit)\n",
    "    \n",
    "    plt.xticks(ticks=range(len(list(x))), labels=list(x),rotation=90)\n",
    "    \n",
    "    # Plot covid confirmed cases \n",
    "    if plot_covid_curves:\n",
    "        for y_country, country,color in zip(y_countries, countries, ['k','gray','darkgray']):\n",
    "            plt.plot(x,y_country, alpha=1,color=color, label='Confirmed cases - {}'.format(country))\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    if zscore:\n",
    "        ylabel += ' (z-score)'\n",
    "    plt.ylabel(ylabel)\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2itfEjA9x0kN"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "# output_dir = './../../datum/reddit/input/'\n",
    "\n",
    "# potential output dir if drive has been mounted:\n",
    "output_dir = '/content/drive/My Drive/reddit_json/'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q1yreZqQx0kQ"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(output_dir+'features_depression_0.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lv5Jvqjtx0kW"
   },
   "outputs": [],
   "source": [
    "# Search reddit\n",
    "# Search unix code https://www.unixtimestamp.com/index.php\n",
    "# Timeline: https://www.nytimes.com/article/coronavirus-timeline.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y267zKogx0kY"
   },
   "outputs": [],
   "source": [
    "# Anxiety corona virus\n",
    "# JAN. 20 Other countries, including the United States, confirmed cases.\n",
    "\"I know this may sound silly, but I\\u2019m scared of the coronavirus. A lot of people are saying it\\u2019s not a big deal and that I\\u2019ll be safe as long as I\\u2019m healthy. I know all of this but I\\u2019m more scared of the fact that this will turn into a pandemic.\"\n",
    "\n",
    "# Other days:\n",
    "# JAN. 30 The W.H.O. declared a global health emergency\n",
    "# The World Health Organization on Feb. 11 proposed an official name for the disease the virus coronavirus causes: Covid-19\n",
    "# Feb 23 Italy sees major surge in coronavirus cases and officials lock down towns.\n",
    "subreddit = 'healthanxiety'\n",
    "date_start = '2020/03/24'\n",
    "date_end = '2020/03/30'\n",
    "\n",
    "start = date2timestamp(date_start)\n",
    "end = date2timestamp(date_end)\n",
    "size = 1000000000\n",
    "url = 'https://api.pushshift.io/reddit/search/submission/?subreddit={}&sort=desc&sort_type=created_utc&after={}&before={}&size={}'.format(subreddit,start, end, size)\n",
    "print(url)\n",
    "# filename = 'scrape_reddit'\n",
    "# filename = filename+'_{}_{}'.format(date_start.replace('/', ''), date_end.replace('/', ''))\n",
    "\n",
    "\n",
    "# Comment so it won't download\n",
    "\n",
    "# url2json(url, output_dir+filename)\n",
    "# anxiety_covid = json2list(output_dir+filename+'.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tGB0v52ex0ka"
   },
   "outputs": [],
   "source": [
    "timestamp2date(1579395379)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5LsxyN-ix0kc"
   },
   "outputs": [],
   "source": [
    "def scrape_reddit(output_dir, subreddit, timeframe, date_start, date_end, size = 1000):\n",
    "    '''\n",
    "    size = {1,1000} #amount of posts\n",
    "    '''\n",
    "    start = date2timestamp(date_start)\n",
    "    end = date2timestamp(date_end)\n",
    "    url = 'https://api.pushshift.io/reddit/search/submission/?subreddit={}&sort=desc&sort_type=created_utc&after={}&before={}&size={}'.format(subreddit,start, end, size)\n",
    "    filename = '{}_{}_{}_{}'.format(subreddit, timeframe, date_start.replace('/', ''), date_end.replace('/', ''))\n",
    "    url2json(url, output_dir+filename)\n",
    "    posts = json2list(output_dir+filename+'.json')\n",
    "    posts_filtered = []\n",
    "    for post in posts:\n",
    "        post_filtered = {}\n",
    "        for key in post.keys():\n",
    "            post_filtered[key]=post.get(key)\n",
    "        posts_filtered.append(post_filtered)\n",
    "    # np.savez_compressed(input_dir+filename+'.npz',posts_filtered)\n",
    "#     os.remove(output_dir+filename+'.json')\n",
    "    return filename\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2zwjY5ukx0kf"
   },
   "outputs": [],
   "source": [
    "date2timestamp(date_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3707,
     "status": "ok",
     "timestamp": 1587255551919,
     "user": {
      "displayName": "Tanya Talkar",
      "photoUrl": "",
      "userId": "12952569726622083567"
     },
     "user_tz": 240
    },
    "id": "FtHU0m1Yx0kh",
    "outputId": "ee03ebe7-1a14-4c08-cb6f-c88f6a2b237e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2020/03/27\n"
     ]
    }
   ],
   "source": [
    "# # Commented so it won't run on accident\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# start = date2timestamp(date_start)\n",
    "# end = date2timestamp(date_end)\n",
    "\n",
    "\n",
    "days = list_of_days(date(2020,3,27), date(2020,3,30))\n",
    "combinations = [['depression', 'post']]\n",
    "size = 1000\n",
    "\n",
    "# Scrape: takes a while\n",
    "for subreddit, timeframe in combinations:\n",
    "    for i in range(len(days))[::3]:\n",
    "        try:\n",
    "            date_start = days[i]\n",
    "            date_end = days[i+3]\n",
    "            i=+ 3\n",
    "        except:\n",
    "            break\n",
    "        print(i)\n",
    "        print(date_start)\n",
    "#         print(subreddit, timeframe, date_start, date_end)\n",
    "        filename = scrape_reddit(output_dir, subreddit, timeframe, date_start, date_end, size = size)\n",
    "#         posts_filtered = np.load(output_dir+filename+'.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PwkdWMrpx0kj"
   },
   "outputs": [],
   "source": [
    "scraped = ['EDAnonymous',\n",
    " 'addiction',\n",
    " 'adhd',\n",
    " 'alcoholism',\n",
    " 'anxiety',\n",
    " 'askdocs',\n",
    " 'askscience',\n",
    " 'atheism',\n",
    " 'bipolarreddit',\n",
    " 'books',\n",
    " 'bpd',\n",
    " 'buddhism',\n",
    " 'christianity',\n",
    " 'depersonalization',\n",
    " 'depression',\n",
    " 'dpdr',\n",
    " 'eatingdisorders',\n",
    " 'features',\n",
    " 'feelgood',\n",
    " 'fitness',\n",
    " 'frugal',\n",
    " 'healthanxiety',\n",
    " 'jokes',\n",
    " 'legaladvice',\n",
    " 'lifeprotips',\n",
    " 'meditation',\n",
    " 'mentalhealth',\n",
    " 'mentalillness',\n",
    " 'mindfulness',\n",
    " 'nostupidquestions',\n",
    " 'paranoia',\n",
    " 'parenting',\n",
    " 'personalfinance',\n",
    " 'psychosis',\n",
    " 'psychoticreddit',\n",
    " 'ptsd',\n",
    " 'randomkindness',\n",
    " 'relationships',\n",
    " 'schizophrenia',\n",
    " 'showerthoughts',\n",
    " 'socialanxiety',\n",
    " 'stopselfharm',\n",
    " 'suicidewatch',\n",
    " 'talesfromcallcenters',\n",
    " 'talesfromretail',\n",
    " 'talesfromtechsupport',\n",
    " 'teaching',\n",
    " 'theoryofreddit',\n",
    " 'writing',\n",
    " 'writingprompts']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nxJ4cFwZx0kk"
   },
   "outputs": [],
   "source": [
    "\n",
    "subreddits = ['mentalhealth',\n",
    " 'socialanxiety',\n",
    " 'buddhism',\n",
    " 'depersonalization',\n",
    " 'randomkindness',\n",
    " 'ptsd',\n",
    " 'alcoholism',\n",
    " 'depression',\n",
    " 'mindfulness',\n",
    " 'mentalillness',\n",
    " 'psychosis',\n",
    " 'suicidewatch',\n",
    " 'atheism',\n",
    " 'bpd',\n",
    " 'fitness',\n",
    " 'adhd',\n",
    " 'stopselfharm',\n",
    " 'parenting',\n",
    " 'meditation',\n",
    " 'healthanxiety',\n",
    " 'teaching',\n",
    " 'relationships',\n",
    " 'schizophrenia',\n",
    " 'personalfinance',\n",
    " 'EDAnonymous',\n",
    " 'jokes',\n",
    " 'addiction',\n",
    " 'anxiety',\n",
    " 'bipolarreddit',\n",
    " 'paranoia',\n",
    " 'christianity',\n",
    " 'legaladvice']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yq4c6Pkbx0km"
   },
   "outputs": [],
   "source": [
    "# # Commented so it won't run on accident\n",
    "\n",
    "\n",
    "# # Load scraped files and Extract features WITHOUT SUMMERIZING\n",
    "\n",
    "# # features.append([subreddit, timeframe, date_range, total_posts] + [a0,a1,b]+c+c1+c2+d)        \n",
    "# columns = ['subreddit','timeframe','date','posts','posts_raw', 'all_words', 'covid_total', 'covid_boolean', 'suicide_total','suicide_bool', ]\n",
    "# sentiment_cols = ['sent_neg','sent_neu', 'sent_pos', 'sent_compound']\n",
    "# # liwc_cols = pd.read_csv(liwc_dir + 'categories.txt', index_col=0)['0'].tolist()\n",
    "# columns = columns+sentiment_cols\n",
    "\n",
    "\n",
    "# covid_words = ['corona','virus','coronavirus', 'pandemic', 'epidemic', 'quarantine', 'covid', 'covid19']\n",
    "# suicide_words = ['end it', \"take it anymore\", 'suicide', 'I will overdose','I want to overdose', 'shoot myself', 'hang myself', 'kill myself', \"hurt myself\", \"cut myself\",  \n",
    "#                 'will miss me', 'if I live or die', 'hopeless'] #Look at suicide note corpus for more\n",
    "\n",
    "# Adam sent these:\n",
    "# suicide_thoughts = ['suicidal', 'to die', 'death', 'kill', 'kill myself', 'want to die', 'suicide', 'to end', 'wanna die', 'wanna kill', 'commit suicide', 'killing myself', 'killing', 'to kill', 'die', 'dying', 'alive', 'live anymore', 'goodbye', 'this world', 'earth', 'end my', 'my life', 'life anymore', 'live anymore', \"i'm done\" \"i'm just done\", 'so done', 'end', 'am done', 'overdose', \"I'm done\", 'end tonight', 'ends tonight', 'I wish', 'just wish', 'sleep forever', 'never wake', 'commit', 'with life', 'wake up', 'shoot me', 'hang myself', 'a bridge', 'to live', 'wanna live', 'dead', 'be dead', 'just die', 'gun']\n",
    "\n",
    "\n",
    "\n",
    "# timeframes = ['post']\n",
    "# combinations = []\n",
    "# for sr in subreddits:\n",
    "#     for t in timeframes:\n",
    "#         combinations.append([sr, t])\n",
    "\n",
    "# days_all = [list_of_days(date(2019, 1, 19), date(2019, 3, 22)), list_of_days(date(2020, 1, 19), date(2020, 3, 22)),] \n",
    "\n",
    "\n",
    "# for subreddit, timeframe in combinations:\n",
    "#     features_df = pd.DataFrame()\n",
    "#     print(subreddit)\n",
    "#     features = []\n",
    "#     if timeframe == 'pre':\n",
    "#         days = days_all[0]\n",
    "#         year = '2019'\n",
    "#     else:\n",
    "#         days = days_all[1]\n",
    "#         year = '2020'\n",
    "#     # For each timepoint \n",
    "\n",
    "#     for i in range(len(days))[::3]:\n",
    "#         try:\n",
    "#             date_start = days[i]\n",
    "#             date_end = days[i+3]\n",
    "#             i=+ 3\n",
    "#         except:\n",
    "#             break\n",
    "#         filename = '{}_{}_{}_{}'.format(subreddit, timeframe, date_start.replace('/', ''), date_end.replace('/', ''))\n",
    "#         # Load 1 timepoint         \n",
    "#         posts = np.load(output_dir+filename+'.npz')['arr_0'] \n",
    "\n",
    "\n",
    "#         posts_raw = [(post['title']+' '+post['selftext']).replace('. ', '.\\n') for post in posts if post['selftext']!=None and post['title']!=None]\n",
    "#         posts = [' '.join((post['title']+' '+post['selftext']).split()) for post in posts if post['selftext']!=None and post['title']!=None]\n",
    "#         date_range = date_start.replace(year+'/', '')+'-'+date_end.replace(year+'/', '')\n",
    "#         # Features         \n",
    "#         word_count_all = [words(post) for post in posts_clean] # count all words\n",
    "#         word_count_covid = [count_words(post, covid_words) for post in posts] # count covid words\n",
    "#         word_count_covid_total = [n[0] for n in word_count_covid] #total\n",
    "#         word_count_covid_bool = [n[1] for n in word_count_covid] #appears at least once in post    \n",
    "#         word_count_suicide = [count_words(post, suicide_words) for post in posts] # count suicide\n",
    "#         word_count_suicide_total = [n[0] for n in word_count_suicide] #total\n",
    "#         word_count_suicide_bool = [n[1] for n in word_count_suicide] #appears at least once in post    \n",
    "        \n",
    "#         sent = [list(sentiment_analysis(post).values()) for post in posts]\n",
    "#         sent0 = [n[0] for n in sent]\n",
    "#         sent1 = [n[1] for n in sent]\n",
    "#         sent2 = [n[2] for n in sent]\n",
    "#         sent3 = [n[3] for n in sent]\n",
    "\n",
    "#         df_day_i = pd.DataFrame([\n",
    "#             [subreddit]*len(posts), \n",
    "#             [timeframe]*len(posts),\n",
    "#             [date_range]*len(posts),\n",
    "#             posts, posts_raw, word_count_all, \n",
    "#             word_count_covid_total, word_count_covid_bool,  word_count_suicide_total, word_count_suicide_bool,\n",
    "#             sent0,sent1,sent2,sent3,\n",
    "#         ]).T\n",
    "#         features_df = pd.concat([features_df, df_day_i])\n",
    "        \n",
    "        \n",
    "# #         d = [liwc(liwc_dir,post) for post in posts] #LIWC\n",
    "# #         d = list(pd.DataFrame(d).mean(axis=0))\n",
    "# #         features.append([subreddit, timeframe, date_range, total_posts] + [a0,a1,b]+c0+c1+d)            \n",
    "#     features_df.columns=columns\n",
    "#     features_df.to_csv(output_dir+'features_{}_0.csv'.format(subreddit), index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "28qAWz2Cx0ko"
   },
   "outputs": [],
   "source": [
    "# Obtain curves for confirmed cases\n",
    "countries = ['China', 'US', 'Italy']\n",
    "scale = 500000\n",
    "\n",
    "y_countries = []\n",
    "\n",
    "for country in countries:\n",
    "    confirmed = pd.read_csv(output_dir+'time_series_covid_19_confirmed.csv')\n",
    "    confirmed_country = confirmed[confirmed['Country/Region']==country]\n",
    "    y_country = confirmed_country.iloc[:,4:].sum().values\n",
    "    y_country = list(y_country[::3]/scale)\n",
    "    # x_country = list(country_country.iloc[:,4:].sum().index)\n",
    "    # x_country = [0]+list(x_country[::3])\n",
    "    y_countries.append(y_country)\n",
    "    \n",
    "len(y_countries[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lNY1ps0Cx0kq"
   },
   "outputs": [],
   "source": [
    "# # How covid is affecting people who might be suicidal\n",
    "# fig = px.scatter(features_df, x=\"date\", y=\"covid_total\", hover_name = 'posts_raw')\n",
    "# fig.show()\n",
    "\n",
    "# # Plot more than one\n",
    "# # trace0 = go.Scatter(x=date, y=features_df.suicide_total.values)#, hover_name = features_df.posts_raw)\n",
    "# # trace1 = go.Scatter(x=date, y=features_df.covid_total.values)#, hover_name = features_df.posts_raw)\n",
    "# # data = [trace0, trace1]\n",
    "# # py.iplot(data, filename='scatter-mode')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I1w7iDgyx0ks"
   },
   "outputs": [],
   "source": [
    "# # Concat extracted features into 1 df:\n",
    "# features_df = pd.read_csv(output_dir+'features_{}.csv'.format('mindfulness'))\n",
    "# print(features_df.shape)\n",
    "# for subreddit in features_extracted:\n",
    "#     if subreddit == 'mindfulness':\n",
    "#         continue\n",
    "#     features = pd.read_csv(output_dir+'features_{}.csv'.format(subreddit))\n",
    "#     features_df = pd.concat([features_df,features])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wmSiERrDx0ku"
   },
   "outputs": [],
   "source": [
    "# subredditsx = ['anxiety', 'healthanxiety']\n",
    "plot_across_time(subreddits,y_col = 'covid_boolean', y_col_div_by = 'total_posts',\n",
    "                  ylabel='Proportion of subReddit posts about COVID19',filter_small = True, small_value = 150, \n",
    "                  plot_raw = True,  plot_line = False, alpha = 0.3, plot_covid_curves = True, zscore = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mdN8cSuOx0kw"
   },
   "outputs": [],
   "source": [
    "### Hypochondriac symptoms predict overall concern 1.5 months before. \n",
    "### All of Reddit converges on the same topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b684nJcEx0ky"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Early:\n",
    "01/19: {'created_utc': 1579618862, 'num_comments': 7, 'title': 'The breaking news stories about the coronavirus is making me really nervous and I’m not sure what to do?', 'selftext': 'I’ve been seeing a lot of news stories today about an incurable, lethal disease originating in China spreading to other countries. I know the media often over exaggerates things like this, but WHO is debating whether or not to declare this an international emergency. Nothing triggers my anxiety worse than things like this, if anyone has any advice on how to cope/can inform me on it I would really appreciate it!', 'score': 1},\n",
    "01/19: {'created_utc': 1579543321, 'num_comments': 1, 'title': 'Wuhan Virus anxiety', 'selftext': \"Right off the bat, i'm not chinese or live anywhere in the eastern part of the globe. But i am a massive hypochondriac and terrified of a global outbreak.  \\n\\n\\nThis morning, i saw an article showing a video of airline passengers being screened by medical personal in hazmat suits. With the article spewing the whole sensationalized clickbait crap about an apocalyptic global epidemic.  \\n\\n\\nAnd after seeing it i quickly spiraled into stress and anxiety. Even though i was able to avoid a full on panic attack, this article bothered me to the point that ll i've been thinking about is an outbreak for the rest of the day just by reading a news article for a few minutes.  \\n\\n\\nI hope everybody in the east can stay safe and healthy, the worst i've had today is nearly having a panic attack. Can't imagine how worrying it is over there.\", 'score': 1},\n",
    "01/25: {'created_utc': 1580175419, 'num_comments': 3, 'title': 'so so so scared', 'selftext': 'this corona virus has me absolutely terrified. i know there\\'s all these \"low mortality\" things, but i read to far into the conspiracies and the videos of chinese hospitals and doctors crying for help. \\n\\nive washed and sanitized my hands to the point they\\'re cracked and bleeding. i won\\'t leave the house anymore unless its 100% necessary.and even when i do i don\\'t touch ANYTHING\\n\\nim so scared, breaking down crying, i can\\'t even eat anymore. nothing the news or cdc says can calm me down because i am fully convinced china is lying and that this could even be a bioweapon. i heard it\\'s mutated already and 300,000-1,000,000 people fled china possibly infected. i feel doomed'}\n",
    "\n",
    "\n",
    "\n",
    "# Suicidality\n",
    "03/16:        {'created_utc': 1584584727, 'num_comments': 0, 'title': 'I feel like a scared child but I have no parents to run to for safety', 'selftext': \"I'm far from being actually alone, I don't even live alone, yet right now with the virus, the economic status, and the high stress everyone is feeling is making me feel like my bones are trying to crawl out of my flesh. I want it to stop, I want to scream and cry, I want to hide and honestly just fucking die so I don't have to live with any of these feelings anymore. I work minimum wage, I'm saving for the house I'm renting in May, but if I lose my job or can't work because of Covid-19 I am absolutely fucked. I am terrified and I feel pinned down by this overwhelming feeling it's all going to get so so much worse...Part of me wishes the world would just end. No worried then. No stress. I'm dreading my state saying we must stay home because my father is bipolar and refuses to go to therapy or get medication so I don't feel safe outside of my room and most of my social interactions outside of work come in arguments with him because he can never be wrong. He has to be right. I wish it would all just freeze or disappear.\", 'score': 1},\n",
    "# Works at hospital\n",
    "03/16:        {'created_utc': 1584581971, 'num_comments': 0, 'title': 'Feeling overwhelmed about corona and working at the hospital', 'selftext': \"I live in New York and work in a hospital. We were short on supplies even before the virus really became a thing here. We don't have masks to give patients. We are not allowed to wear masks ourself. We have been mandated to work and even been told to continue coming to work even if we have had contact with a confirmed positive. We just have to take our temperature daily &amp; we are only to wear a mask if we have active respiratory symptoms.\\n\\nI have constant shortness of breath and chest pains and pressure due to anxiety which has me constantly stressed. My throat is super dry and idk why. Dry throat and stress leaves you more susceptible to infection in addition to working in a war zone with no protection daily.\\n\\nI feel so anxious and overwhelmed. I was finally getting my panic attacks sorta under control by going out mor and starting therapy. That's all on hold for the indefinite future. Im constantly afraid of having another panic attack or being in the position where I feel like I'm actually dying and unable to see a provider due to the system being overwhelmed.\\n\\nThe only positive thing I have going on right now is that its about to be spring and I can garden while social distancing.\", 'score': 1},\n",
    "# Buying guns\n",
    "03/16:        {'created_utc': 1584581413, 'num_comments': 24, 'title': 'Are we going to all die and go into an apocalypse? The media is starting to freak me out because of the Corona Virus', 'selftext': \"I keep on seeing the Corona Virus everywhere now I hear people are buying guns then people are talking about Germany and how bad it is there. I thought that America was handling it very well. And we are on top of it? I'm freaking out. Am I overthinking between all the youtube posts I'm buggin.\", 'score': 0},\n",
    "\n",
    "03/16:        {'created_utc': 1584574890, 'num_comments': 1, 'title': 'My mom is driving herself crazy because of the COVID-19', 'selftext': 'My mom never have suffer from anxiety or other mental illness like OCD, etc. \\nSince the COVID-19, we steam and sanitize our house all the day with the steamer machine, we use other product like Clorox or Javex, if she touches something in the house she wash her hand, I suffer from anxiety and it doesn’t help at all! I feel stress will kill our brain before the COVID-19, I’m tired, really tired, I want just this stupid virus to end and to go out. All we do is talking about this virus, the media is not helping at all... my head is gonna explode.', 'score': 3},\n",
    "# GAD + Isolation  \n",
    "      {'created_utc': 1584570369, 'num_comments': 0, 'title': 'Being single and living alone is absolutely brutal right now.', 'selftext': 'I live with generalized anxiety disorder and already have major anxiety regarding my health. Had the flu end of January pretty bad and then hives post flu- I’m miserable and was finally getting back on track and then this.\\n\\n\\nI am terrified. Just being alone all day. And can’t see my parents or friends. Or brother. I have been so anxious through all of this for many reasons. \\n\\nfinally got the work from home okay on Monday but now being told by higher ups where I work (a health science college at a major uni) that someone needs to be in my office during the day, though it’s not essential. I hate the idea of going to my office which is connected to the main hospital in my city.\\n\\nAnyway. I really could use some people to talk to as I don’t have that many friends and that’s what I need now. I need some more connections and chances to get to other people and distract from the virus.\\n\\nThanks', 'score': 0},\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SMdSlU7Rx0kz"
   },
   "outputs": [],
   "source": [
    "subreddits2 = ['relationships','mindfulness', 'healthanxiety', 'anxiety', 'suicidewatch', 'depression', 'ptsd', 'adhd', \n",
    "              'bpd', 'paranoia', 'socialanxiety', 'schizophrenia', 'bipolarreddit', 'alcoholism', 'addiction',]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6qcME7F5x0k1"
   },
   "source": [
    "### Social anxiety: less posts, more words on average per post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GAeFCxI0x0k1"
   },
   "outputs": [],
   "source": [
    "plot_across_time(subreddits2, y_col = 'total_posts', y_col_div_by = False, zscore = False, \n",
    "                 ylabel='Total posts',\n",
    "                 small_value = 150, plot_raw = True, \n",
    "                     plot_line = True, alpha = 0.1, plot_covid_curves = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YFgZOIkOx0k3"
   },
   "outputs": [],
   "source": [
    "plot_across_time(subreddits2, y_col = 'total_posts', y_col_div_by = False, zscore = True, \n",
    "                 ylabel='Total posts',\n",
    "                 small_value = 150, plot_raw = True, \n",
    "                     plot_line = True, alpha = 0.1, plot_covid_curves = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tv6kgWcvx0k5"
   },
   "outputs": [],
   "source": [
    "plot_across_time(subreddits2, y_col = 'all_words', y_col_div_by = 'total_posts', \n",
    "                 ylabel='Average words per post',\n",
    "                 small_value = 150, plot_raw = True, zscore = True,\n",
    "                     plot_line = True, alpha = 0.3, plot_covid_curves = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1d78WAv7x0k7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vCr2XpChx0k_"
   },
   "source": [
    "# Sentiment analysis: social anxiety getting less negative!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i_8_t2SWx0k_"
   },
   "outputs": [],
   "source": [
    "plot_across_time(subreddits, y_col = 'sent_neg', y_col_div_by = False, \n",
    "                 ylabel='Average negative sentiments',zscore = True,\n",
    "                 filter_small = True, small_value = 200, plot_raw = False, \n",
    "                     plot_line = True, alpha = 0.1, plot_covid_curves = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WGBf6pUhx0lB"
   },
   "outputs": [],
   "source": [
    "\n",
    "# input y variable across time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OAtEVab6x0lC"
   },
   "outputs": [],
   "source": [
    "subreddit = 'socialanxiety'\n",
    "y_col = 'sent_neg'\n",
    "df_subreddit = pd.read_csv(output_dir+'features_{}_0.csv'.format(subreddit))\n",
    "\n",
    "# Load data\n",
    "xs = list(set(df_subreddit.date.values))\n",
    "try: xs.remove(np.nan)\n",
    "except: pass\n",
    "xs.sort()\n",
    "ys = []\n",
    "cs = []\n",
    "for day in xs:\n",
    "    df_subreddit_day = df_subreddit[df_subreddit.date == day]\n",
    "    y = df_subreddit_day[y_col].values\n",
    "    ys.append(y)\n",
    "    median_value = int(np.median(y))\n",
    "    median_max = np.percentile(y,90)\n",
    "    color = median_max*10**2\n",
    "    color = np.max(y)*10**2\n",
    "    cs.append('hsl({}%,50%,50%)'.format(color))\n",
    "\n",
    "\n",
    "# plot\n",
    "fig = go.Figure(data=[go.Box(\n",
    "    y=ys[i],\n",
    "    marker_color=cs[i],\n",
    "    name = xs[i],\n",
    "    ) for i in range(len(xs))])\n",
    "\n",
    "# format the layout\n",
    "fig.layout.update(\n",
    "    xaxis=dict(showgrid=False, zeroline=False, showticklabels=True,   ticktext = xs),\n",
    "    yaxis=dict(zeroline=False, gridcolor='white'),\n",
    "    paper_bgcolor='rgb(233,233,233)',\n",
    "    plot_bgcolor='rgb(233,233,233)',\n",
    "    showlegend=False,\n",
    "    title=y_col+' as COVID-19 grows'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yRMaftYVx0lE"
   },
   "outputs": [],
   "source": [
    "subreddit = 'socialanxiety'\n",
    "df_subreddit = pd.read_csv(output_dir+'features_{}_0.csv'.format(subreddit))\n",
    "fig = px.scatter(df_subreddit, x=\"date\", y=\"sent_neg\", color=\"suicide_bool\",hover_name='posts',\n",
    "                 title=subreddit)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KscHfyThx0lF"
   },
   "source": [
    "### Suicidality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s915VwUcx0lG"
   },
   "outputs": [],
   "source": [
    "subreddit = 'suicidewatch'\n",
    "df_subreddit = pd.read_csv(output_dir+'features_{}_0.csv'.format(subreddit))\n",
    "fig = px.scatter(df_subreddit, x=\"date\", y=\"sent_neg\", color=\"sent_neg\",hover_name='posts',\n",
    "                 title=\"Numeric 'size' values mean continous color\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y28UNsLsx0lH"
   },
   "outputs": [],
   "source": [
    "subreddit = 'suicidewatch'\n",
    "df_subreddit = pd.read_csv(output_dir+'features_{}_0.csv'.format(subreddit))\n",
    "fig = px.scatter(df_subreddit, x=\"date\", y=\"sent_neg\", color=\"covid_boolean\",hover_name='posts',\n",
    "                 title=subreddit+' with COVID-19 related posts in yellow')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qe0CwB2Gx0lJ"
   },
   "outputs": [],
   "source": [
    "subreddit = 'socialanxiety'\n",
    "df_subreddit = pd.read_csv(output_dir+'features_{}_0.csv'.format(subreddit))\n",
    "fig = px.scatter(df_subreddit, x=\"date\", y=\"sent_neg\", color=\"suicide_bool\",hover_name='posts',\n",
    "                 title=subreddit+' with suicidal related posts in yellow')\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uprXfYLox0lK"
   },
   "outputs": [],
   "source": [
    "# The fact that it may be affecting ED more or certain disorders more could be useful\n",
    "# How personal finance may be connected to mental could be studied: If personal finance become more similar to some disorder (tfidf))\n",
    "# Target at risk people who post regularly and stopped posting? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o_yiS8Ikx0lM"
   },
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0MfxSTr0x0lM"
   },
   "outputs": [],
   "source": [
    "# reload(extract_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3UX6EjHNx0lO"
   },
   "outputs": [],
   "source": [
    "# Create a corpus to build the matrix\n",
    "posts_all = []\n",
    "for sr in subreddits2:\n",
    "    df_subreddit = pd.read_csv(output_dir+'features_{}_0.csv'.format(sr))\n",
    "    posts = df_subreddit.posts.values\n",
    "    posts_all.append(posts)\n",
    "    \n",
    "\n",
    "corpus = [n for i in posts_all for n in i]\n",
    "# remove nan\n",
    "corpus = [n for n in corpus if isinstance(n,str)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qsZayYtzx0lP"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(lowercase=True, ngram_range=(1,3), stop_words='english',\n",
    "                        max_features=512, min_df=2, max_df=0.8)\n",
    "\n",
    "\n",
    "\n",
    "# Build matrix\n",
    "vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "js5MYse5x0lR"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t8fGwa6Jx0lS"
   },
   "outputs": [],
   "source": [
    "# Comment so it won't run\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "69_HjAsgx0lU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y9_vPbrMx0lW"
   },
   "outputs": [],
   "source": [
    "feature_array = np.array(vectorizer.get_feature_names())\n",
    "n = 15\n",
    "\n",
    "split = 0.9\n",
    "\n",
    "\n",
    "\n",
    "for sr in subreddits2:\n",
    "    df_subreddit = pd.read_csv(output_dir+'features_{}_0.csv'.format(sr))\n",
    "    posts = df_subreddit.posts.values\n",
    "    posts = [n for n in posts if isinstance(n,str)]\n",
    "    split_i = int(len(posts)*split)\n",
    "    posts_before = posts[:split_i]\n",
    "    posts_after = posts[split_i:]\n",
    "    posts2 = [posts_before, posts_after]\n",
    "    posts_names = ['before', 'after']\n",
    "    for i in range(2):\n",
    "        response = vectorizer.transform(posts2[i])\n",
    "        tfidf_sorting = np.argsort(response.toarray()).flatten()[::-1]\n",
    "        top_n = feature_array[tfidf_sorting][:n]\n",
    "        print('\\n====={}==={}'.format(sr, posts_names[i]))\n",
    "        print(top_n)\n",
    "    print('\\n\\n===============')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j3v21pERx0lY"
   },
   "outputs": [],
   "source": [
    "# # Alternative method\n",
    "# def tfidf(X_train_sentences = posts, lower_case = True, ngram_range = (1,3), max_features=512, min_df=2, max_df=0.8, model = 'svm'):\n",
    "#     sw = stopwords.words('english')\n",
    "#     vectorizer = TfidfVectorizer(lowercase=lower_case, ngram_range=ngram_range, stop_words=sw,max_features=max_features, min_df=min_df, max_df=max_df)\n",
    "#     train_vectors = vectorizer.fit_transform(X_train_sentences).toarray()\n",
    "#     feature_names = vectorizer.get_feature_names()\n",
    "#     feature_names = ['tfidf_'+n for n in feature_names]\n",
    "#     return train_vectors, feature_names\n",
    "    \n",
    "# X_test_sentences = False\n",
    "# vectors, feature_names = tfidf(X_train_sentences = posts_all_days, lower_case = True, ngram_range = (1,3), max_features=512, min_df=2, max_df=0.8, model = 'svm')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QoMkLFuHx0lZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8W2y7VAjx0lb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kXYULKaAx0ld"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LKz6bEd7x0lf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "reddit.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
